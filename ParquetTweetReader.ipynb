{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet reader for tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be used to read and analyze data from Parquet-file.\n",
    "Example is using twitter data stored to Parquet-format using KafkaTwitterTopic-to-Parquet notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T10:10:57.403349Z",
     "start_time": "2019-07-23T10:10:56.886152Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spark, Spark SQL and add operator libraries we'll need to process data\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T10:11:09.578811Z",
     "start_time": "2019-07-23T10:10:57.406085Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Spark Session \n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Parquet reader\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T11:29:01.649439Z",
     "start_time": "2019-07-23T11:28:56.578108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading data from Parquet file\n",
    "df = spark.read.parquet(\"data/tweets.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T11:29:03.977534Z",
     "start_time": "2019-07-23T11:29:02.500187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10548"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting lines\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T11:29:09.154450Z",
     "start_time": "2019-07-23T11:29:09.146810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- tweet_id: long (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- screen_name: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing schema and showing sample from beginning of dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "SQL queries for some simple sample operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T14:10:12.751456Z",
     "start_time": "2019-07-23T14:10:12.698385Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating temporary table for SQL queries\n",
    "df.createOrReplaceTempView('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T14:16:57.909211Z",
     "start_time": "2019-07-23T14:16:57.893362Z"
    }
   },
   "outputs": [],
   "source": [
    "# Counting occurences of some of our keywords\n",
    "marathon = spark.sql(\"SELECT count(*) AS marathon FROM table WHERE text LIKE '%marathon%'\")\n",
    "jogging = spark.sql(\"SELECT count(*) AS jogging FROM table WHERE text LIKE '%jogging%'\")\n",
    "trailrunning = spark.sql(\"SELECT count(*) AS trailrunning FROM table WHERE text LIKE '%trailrunning%'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T14:18:21.511757Z",
     "start_time": "2019-07-23T14:18:20.106997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|marathon|\n",
      "+--------+\n",
      "|     236|\n",
      "+--------+\n",
      "\n",
      "+-------+\n",
      "|jogging|\n",
      "+-------+\n",
      "|    101|\n",
      "+-------+\n",
      "\n",
      "+------------+\n",
      "|trailrunning|\n",
      "+------------+\n",
      "|           5|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "marathon.show()\n",
    "jogging.show()\n",
    "trailrunning.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T14:22:21.441708Z",
     "start_time": "2019-07-23T14:22:21.417032Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's see the most active users\n",
    "users = spark.sql(\"SELECT user_name, screen_name, count(*) AS lkm FROM table GROUP BY user_name, screen_name ORDER BY lkm DESC\")\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T14:22:33.670793Z",
     "start_time": "2019-07-23T14:22:28.744726Z"
    }
   },
   "outputs": [],
   "source": [
    "# And tweets of the most active\n",
    "mostactive = spark.sql(\"SELECT * FROM table WHERE screen_name LIKE '_pick_most_active_user_screen_name_from_list_above_'\")\n",
    "mostactive.select('text').show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T14:23:07.125937Z",
     "start_time": "2019-07-23T14:23:07.108256Z"
    }
   },
   "source": [
    "It seems that 'running' isn't good keyword to capture tweets about running sports. Those tweets by most active tweeter seems to be about running tap water..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's try something else. Let's count the words of all text-columns and sort them descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T11:33:03.731100Z",
     "start_time": "2019-07-23T11:33:00.382477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 6905),\n",
       " ('rt', 6689),\n",
       " ('running', 5783),\n",
       " ('to', 3707),\n",
       " ('and', 3563),\n",
       " ('of', 3049),\n",
       " ('a', 2730),\n",
       " ('is', 2160),\n",
       " ('in', 1870),\n",
       " ('on', 1675)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is done by using lambda operations with Sparks RDD data structure.\n",
    "# text-column is 6th column of data, so when first one is 0, we need to look at column 5.\n",
    "# Making words lowercase and splitting lines by spaces. \n",
    "# Then transforming words to tuples with number one. After that add words and count ones. Sort by number on descending order\n",
    "counts = df.rdd.map(lambda x: x[5]) \\\n",
    "            .flatMap(lambda x: x.lower().split(' ')) \\\n",
    "            .map(lambda x: (x, 1)) \\\n",
    "            .reduceByKey(add).sortBy(lambda x: -x[1])\n",
    "            \n",
    "counts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
